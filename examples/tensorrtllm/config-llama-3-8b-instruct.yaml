backend: tensorrtllm

source:
  type: huggingface
  id: meta-llama/Meta-Llama-3-8B-Instruct

tensorrtllm:
  convert_checkpoint_type: "llama"

  convert_checkpoint_args:
    - "--dtype=float16"
  trtllm_build_args:
    - "--gemm_plugin=float16"
    - "--gpt_attention_plugin=float16"
    - "--max_batch_size=128"
    - "--max_input_len=1024"
    - "--max_output_len=1024"
